{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark DataFrame basics\n",
    "\n",
    "Install the PySpark library using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Package import\n",
    "!pip install --user --upgrade pip\n",
    "!pip install --user pyspark\n",
    "!pip install --user pandas==1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "## PySpark\n",
    "import pyspark\n",
    "from pyspark.sql.functions import isnan, isnull\n",
    "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
    "from pyspark.sql import Window, SparkSession, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Imputer,VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Random Dataset\n",
    "Create a random dataset with columns like name, age, salary, company, and position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random dataset\n",
    "\n",
    "# Function to generate a random name and position\n",
    "def generate_name_and_position():\n",
    "    first_names = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Emma\", \"Frank\", \"Grace\", \"Henry\", \"Ivy\", \"Jack\"]\n",
    "    last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Jones\", \"Brown\", \"Davis\", \"Miller\", \"Wilson\", \"Moore\", \"Taylor\"]\n",
    "\n",
    "    # .001% chance of being a C-suite or board member\n",
    "    if random.random() < 0.0001:\n",
    "        positions = [\"CEO\", \"CTO\", \"CFO\", \"CMO\", \"COO\", \"Chairman\", \"Board Member\"]\n",
    "        position = random.choice(positions)\n",
    "    else:\n",
    "        positions = [\"Data Scientist\", \"Machine Learning Engineer\", \"Data Engineer\", \"Data Analyst\", \"AI Researcher\",\n",
    "                     \"Intern\", \"HR\", \"Manager\", \"Product Owner\", \"Developer\"]\n",
    "        position = random.choice(positions)\n",
    "\n",
    "    return f\"{random.choice(first_names)} {random.choice(last_names)}\", position\n",
    "\n",
    "# Function to generate a random company name\n",
    "def generate_company_name():\n",
    "    company_suffixes = [\"Technologies\", \"Solutions\", \"Innovations\", \"Labs\", \"Systems\", \"Analytics\"]\n",
    "    company_prefixes = ['Alpha', 'Beta', 'Gamma', 'Delta','Meta']\n",
    "    company_name = f\"{random.choice(company_prefixes)} {random.choice(company_suffixes)}\"\n",
    "    \n",
    "    return company_name\n",
    "\n",
    "\n",
    "# Function to generate random years of experience, age, and salary with some null values\n",
    "def generate_experience_age_salary():\n",
    "    experience = random.randint(0, 10)\n",
    "    age = random.randint(18, 65)\n",
    "    salary = random.randint(8000, 120000)\n",
    "\n",
    "    return experience, age, salary\n",
    "def generate_csv(n,file_name):\n",
    "\n",
    "    # Generate random data for 10000 rows\n",
    "    data = [(*generate_name_and_position(), *generate_experience_age_salary(),generate_company_name()) for _ in range(n)]\n",
    "\n",
    "    # Convert data to DataFrame\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Position', 'Experience', 'Age', 'Salary','Company'])\n",
    "\n",
    "    # Randomly remove values within each column\n",
    "    for col in df.columns:\n",
    "        # 10% chance of setting a value to NaN in each column\n",
    "        df.loc[df.sample(frac=0.1).index, col] = np.nan\n",
    "\n",
    "    # Write data to CSV file\n",
    "    csv_file_path = file_name\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_line_tool (n,file_name):\n",
    "    \n",
    "    !python generate_csv.py n file_name\n",
    "\n",
    "command_line_tool (1000,'test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'test1.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "generate_csv(5000000,'test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark Session\n",
    "Initializing a Spark session with SparkSession.builder.appName(\"example\").getOrCreate() creates a connection to a Spark cluster, allowing you to use Spark functionality in your Jupyter notebook. The \"example\" is the application name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a spark session\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Sessions: Local vs. Cloud\n",
    "\n",
    "When working with Apache Spark locally, you typically create only one Spark session in your application as it uses all available CPU cores on your machine. Creating multiple Spark sessions in a local mode might lead to resource conflicts - Each session would try to utilize the same resources.It is typically meant for development and testing purposes and more appropriate to use Spark's built-in parallel processing capabilitie\n",
    "\n",
    "In a cloud environment, such as on platforms like Amazon EMR, Google Dataproc, or Databricks, you can create multiple Spark sessions because these platforms manage the distribution and allocation of resources across a cluster of machines. Each Spark session in a cloud environment is associated with one or more executor nodes in the cluster.\n",
    "\n",
    "### Why Multiple Spark Sessions in the Cloud?\n",
    "\n",
    "1. **Distributed Environment:**\n",
    "   - In the cloud, Spark operates in a distributed environment, and each Spark session can be associated with different parts of the cluster.\n",
    "\n",
    "2. **Resource Management:**\n",
    "   - Cloud platforms handle resource management, allocating resources like CPU, memory, and storage to each Spark session independently. This allows multiple Spark sessions to run concurrently without resource conflicts.\n",
    "\n",
    "3. **Scalability:**\n",
    "   - Cloud environments allow you to scale the number of nodes in your Spark cluster based on your processing needs. This scalability facilitates the creation of multiple Spark sessions to handle different workloads concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://run-6592b0ee04fecf02bacf13a4-ttfqf:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f48b7d91090>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark =SparkSession.builder.appName('Practise').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a Dataset\n",
    "\n",
    "Reading a CSV file with PySpark's `spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\")` function lets Spark automatically infer the schema of the DataFrame based on the data types of columns. The \"header\" option indicates that the first row of the CSV file contains column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- Experience: double (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Salary: double (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.option('header','true').csv('test1.csv',inferSchema=True,header=True )\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Operations\n",
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+------------------+\n",
      "|          Name|            Position|Experience| Age|  Salary|           Company|\n",
      "+--------------+--------------------+----------+----+--------+------------------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|   Gamma Solutions|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|              null|\n",
      "|          null|Machine Learning ...|       2.0|51.0| 22728.0|     Alpha Systems|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|    Meta Analytics|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|        Gamma Labs|\n",
      "|Henry Williams|                null|       2.0|26.0| 81062.0| Meta Technologies|\n",
      "|          null|              Intern|      null|58.0| 53429.0|  Beta Innovations|\n",
      "|          null|             Manager|       7.0|20.0| 37876.0|Delta Technologies|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|    Meta Analytics|\n",
      "|          null|                null|       3.0|null| 53073.0| Delta Innovations|\n",
      "+--------------+--------------------+----------+----+--------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting, Indexing and Checking the Datatypes of the Column(Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+\n",
      "|          Name| Age|\n",
      "+--------------+----+\n",
      "|  Ivy Williams|30.0|\n",
      "|  Bob Williams|58.0|\n",
      "|          null|51.0|\n",
      "| Charlie Brown|39.0|\n",
      "|Frank Williams|57.0|\n",
      "+--------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('Name','Age').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'),\n",
       " ('Position', 'string'),\n",
       " ('Experience', 'double'),\n",
       " ('Age', 'double'),\n",
       " ('Salary', 'double'),\n",
       " ('Company', 'string')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[summary: string, Name: string, Position: string, Experience: string, Age: string, Salary: string, Company: string]\n",
      "+-------+-----------+-------------+------------------+------------------+------------------+-----------------+\n",
      "|summary|       Name|     Position|        Experience|               Age|            Salary|          Company|\n",
      "+-------+-----------+-------------+------------------+------------------+------------------+-----------------+\n",
      "|  count|    4500000|      4500000|           4500000|           4500000|           4500000|          4500000|\n",
      "|   mean|       null|         null| 5.001912222222222| 41.49889266666667|63980.533792222224|             null|\n",
      "| stddev|       null|         null|3.1605540489825565|13.858792239732075|32324.683588721702|             null|\n",
      "|    min|Alice Brown|AI Researcher|               0.0|              18.0|            8000.0|  Alpha Analytics|\n",
      "|    max|Jack Wilson|Product Owner|              10.0|              65.0|          120000.0|Meta Technologies|\n",
      "+-------+-----------+-------------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_spark.describe())\n",
    "df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding and Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+---------------+---------+\n",
      "|          Name|            Position|Experience| Age|  Salary|        Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+---------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|Gamma Solutions|   1993.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|           null|   1965.0|\n",
      "|          null|Machine Learning ...|       2.0|51.0| 22728.0|  Alpha Systems|   1972.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0| Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|     Gamma Labs|   1966.0|\n",
      "+--------------+--------------------+----------+----+--------+---------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding column into dataframe\n",
    "df_spark = df_spark.withColumn('Year Born',2023-df_spark['Age'])\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+---------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|        Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+---------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|Gamma Solutions|   1993.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|           null|   1965.0|\n",
      "|          null|Machine Learning ...|       2.0|51.0| 22728.0|  Alpha Systems|   1972.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0| Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|     Gamma Labs|   1966.0|\n",
      "+--------------+--------------------+----------+----+--------+---------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = df_spark.withColumnRenamed('Name','Full Name')\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using `df_spark.show()` displays the first few rows of the Spark DataFrame, providing a quick overview of the data. `df_spark.printSchema()` prints the schema of the DataFrame, revealing the data types and structure of each column. These actions aid in understanding the content and structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|          Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|  Gamma Solutions|   1993.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|   Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|       Gamma Labs|   1966.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|   Meta Analytics|   1987.0|\n",
      "|  Frank Wilson|             Manager|       8.0|47.0|107395.0|Beta Technologies|   1976.0|\n",
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop all rows with atleast one NA or Null\n",
    "df_spark.na.drop().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|          Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|  Gamma Solutions|   1993.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|   Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|       Gamma Labs|   1966.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|   Meta Analytics|   1987.0|\n",
      "|  Frank Wilson|             Manager|       8.0|47.0|107395.0|Beta Technologies|   1976.0|\n",
      "|     Ivy Brown|             Manager|       1.0|48.0|104867.0|    Alpha Systems|   1975.0|\n",
      "|    Emma Smith|       Data Engineer|       2.0|30.0| 60924.0|     Meta Systems|   1993.0|\n",
      "| Charlie Jones|             Manager|      10.0|54.0| 15520.0|  Gamma Analytics|   1969.0|\n",
      "|  Frank Miller|       AI Researcher|       3.0|28.0|108255.0| Beta Innovations|   1995.0|\n",
      "|   Henry Smith|           Developer|      10.0|41.0| 52975.0|  Alpha Solutions|   1982.0|\n",
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|           Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|   Gamma Solutions|   1993.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|              null|   1965.0|\n",
      "|          null|Machine Learning ...|       2.0|51.0| 22728.0|     Alpha Systems|   1972.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|    Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|        Gamma Labs|   1966.0|\n",
      "|Henry Williams|                null|       2.0|26.0| 81062.0| Meta Technologies|   1997.0|\n",
      "|          null|              Intern|      null|58.0| 53429.0|  Beta Innovations|   1965.0|\n",
      "|          null|             Manager|       7.0|20.0| 37876.0|Delta Technologies|   2003.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|    Meta Analytics|   1987.0|\n",
      "|          null|                null|       3.0|null| 53073.0| Delta Innovations|     null|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop all rows with atleast one NA or Null\n",
    "# how can have two attributes. all/any. Default is 'any'\n",
    "df_spark.na.drop(how='any').show(10)\n",
    "df_spark.na.drop(how='all').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|           Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|   Gamma Solutions|   1993.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|              null|   1965.0|\n",
      "|          null|Machine Learning ...|       2.0|51.0| 22728.0|     Alpha Systems|   1972.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|    Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|        Gamma Labs|   1966.0|\n",
      "|Henry Williams|                null|       2.0|26.0| 81062.0| Meta Technologies|   1997.0|\n",
      "|          null|              Intern|      null|58.0| 53429.0|  Beta Innovations|   1965.0|\n",
      "|          null|             Manager|       7.0|20.0| 37876.0|Delta Technologies|   2003.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|    Meta Analytics|   1987.0|\n",
      "|          null|                null|       3.0|null| 53073.0| Delta Innovations|     null|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using threshold along with any. \n",
    "# if 'thresh=2', then there should be atleast two non-null values and the row won't remove the row \n",
    "df_spark.na.drop(how='any',thresh=2).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|          Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|  Gamma Solutions|   1993.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|             null|   1965.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|   Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|       Gamma Labs|   1966.0|\n",
      "|Henry Williams|                null|       2.0|26.0| 81062.0|Meta Technologies|   1997.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|   Meta Analytics|   1987.0|\n",
      "|  Frank Wilson|             Manager|       8.0|47.0|107395.0|Beta Technologies|   1976.0|\n",
      "|     Ivy Brown|             Manager|       1.0|48.0|104867.0|    Alpha Systems|   1975.0|\n",
      "|    Emma Smith|       Data Engineer|       2.0|30.0| 60924.0|     Meta Systems|   1993.0|\n",
      "|   Jack Miller|                  HR|       0.0|19.0|105439.0|             null|   2004.0|\n",
      "+--------------+--------------------+----------+----+--------+-----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using subset.\n",
    "# remove rows that have 'null' in one column\n",
    "df_spark.na.drop(how='any',subset='Full Name').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|           Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|   Gamma Solutions|   1993.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|               NaN|   1965.0|\n",
      "|           NaN|Machine Learning ...|       2.0|51.0| 22728.0|     Alpha Systems|   1972.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|    Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|        Gamma Labs|   1966.0|\n",
      "|Henry Williams|                 NaN|       2.0|26.0| 81062.0| Meta Technologies|   1997.0|\n",
      "|           NaN|              Intern|      null|58.0| 53429.0|  Beta Innovations|   1965.0|\n",
      "|           NaN|             Manager|       7.0|20.0| 37876.0|Delta Technologies|   2003.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|    Meta Analytics|   1987.0|\n",
      "|           NaN|                 NaN|       3.0|null| 53073.0| Delta Innovations|     null|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.fill('NaN').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|           Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|   Gamma Solutions|   1993.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|              null|   1965.0|\n",
      "|          null|Machine Learning ...|       2.0|51.0| 22728.0|     Alpha Systems|   1972.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|    Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|        Gamma Labs|   1966.0|\n",
      "|Henry Williams|                null|       2.0|26.0| 81062.0| Meta Technologies|   1997.0|\n",
      "|          null|              Intern|       0.0|58.0| 53429.0|  Beta Innovations|   1965.0|\n",
      "|          null|             Manager|       7.0|20.0| 37876.0|Delta Technologies|   2003.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|    Meta Analytics|   1987.0|\n",
      "|          null|                null|       3.0| 0.0| 53073.0| Delta Innovations|     null|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.na.fill(0,['Age','Experience','Salary']).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Operations\n",
    "\n",
    "In this Video We will Cover \n",
    "- Pyspark Dataframes \n",
    "- Filter Operation \n",
    "- &, |, == \n",
    "- ~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+-------+------------------+---------+\n",
      "|     Full Name|            Position|Experience| Age| Salary|           Company|Year Born|\n",
      "+--------------+--------------------+----------+----+-------+------------------+---------+\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0|26085.0|              null|   1965.0|\n",
      "|          null|Machine Learning ...|       2.0|51.0|22728.0|     Alpha Systems|   1972.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0|38455.0|    Meta Analytics|   1984.0|\n",
      "|          null|              Intern|      null|58.0|53429.0|  Beta Innovations|   1965.0|\n",
      "|          null|             Manager|       7.0|20.0|37876.0|Delta Technologies|   2003.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0|10997.0|    Meta Analytics|   1987.0|\n",
      "|          null|                null|       3.0|null|53073.0| Delta Innovations|     null|\n",
      "| Charlie Jones|             Manager|      10.0|54.0|15520.0|   Gamma Analytics|   1969.0|\n",
      "|   Henry Smith|           Developer|      10.0|41.0|52975.0|   Alpha Solutions|   1982.0|\n",
      "|   Grace Davis|                  HR|       6.0|53.0|58698.0|        Alpha Labs|   1970.0|\n",
      "|     Ivy Smith|       Data Engineer|       1.0|42.0|54994.0|     Gamma Systems|   1981.0|\n",
      "|  Grace Miller|       Product Owner|       1.0|40.0|47971.0|     Delta Systems|   1983.0|\n",
      "| Jack Williams|           Developer|       2.0|35.0|44983.0|   Delta Analytics|   1988.0|\n",
      "|     Bob Brown|             Manager|       4.0|61.0|51895.0|         Beta Labs|   1962.0|\n",
      "|   David Moore|       Data Engineer|       7.0|46.0|54699.0|     Gamma Systems|   1977.0|\n",
      "|Henry Williams|                null|       8.0|null|26189.0|   Gamma Analytics|     null|\n",
      "| Charlie Smith|       Data Engineer|       8.0|46.0|52264.0|     Delta Systems|   1977.0|\n",
      "|   David Brown|           Developer|       5.0|40.0|51822.0|     Delta Systems|   1983.0|\n",
      "|    Bob Taylor|                null|       4.0|58.0|51520.0|   Gamma Solutions|   1965.0|\n",
      "|    Emma Smith|      Data Scientist|       8.0|57.0|28407.0|     Delta Systems|   1966.0|\n",
      "+--------------+--------------------+----------+----+-------+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Salary less than or equal to 20000\n",
    "df_spark.filter(\"Salary<=60000\").show()\n",
    "# Other method  df_spark.filkter(df_spark['Salary']<=60000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|           Company|Year Born|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|   Gamma Solutions|   1993.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|              null|   1965.0|\n",
      "|          null|Machine Learning ...|       2.0|51.0| 22728.0|     Alpha Systems|   1972.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|    Meta Analytics|   1984.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|        Gamma Labs|   1966.0|\n",
      "|Henry Williams|                null|       2.0|26.0| 81062.0| Meta Technologies|   1997.0|\n",
      "|          null|              Intern|      null|58.0| 53429.0|  Beta Innovations|   1965.0|\n",
      "|          null|             Manager|       7.0|20.0| 37876.0|Delta Technologies|   2003.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|    Meta Analytics|   1987.0|\n",
      "|          null|                null|       3.0|null| 53073.0| Delta Innovations|     null|\n",
      "|  Frank Wilson|             Manager|       8.0|47.0|107395.0| Beta Technologies|   1976.0|\n",
      "|     Ivy Brown|             Manager|       1.0|48.0|104867.0|     Alpha Systems|   1975.0|\n",
      "|    Emma Smith|       Data Engineer|       2.0|30.0| 60924.0|      Meta Systems|   1993.0|\n",
      "|   Jack Miller|                  HR|       0.0|19.0|105439.0|              null|   2004.0|\n",
      "| Charlie Jones|             Manager|      10.0|54.0| 15520.0|   Gamma Analytics|   1969.0|\n",
      "|  Frank Miller|       AI Researcher|       3.0|28.0|108255.0|  Beta Innovations|   1995.0|\n",
      "|     Ivy Davis|                null|       0.0|18.0| 87162.0|  Meta Innovations|   2005.0|\n",
      "|   Henry Smith|           Developer|      10.0|41.0| 52975.0|   Alpha Solutions|   1982.0|\n",
      "|    Emma Moore|Machine Learning ...|       2.0|38.0| 74904.0|Alpha Technologies|   1985.0|\n",
      "|   Grace Davis|                  HR|       6.0|53.0| 58698.0|        Alpha Labs|   1970.0|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.filter((df_spark['Salary']>=60000) | (df_spark['Salary']<=75000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+----------+----+--------+-----------------+---------+\n",
      "|      Full Name|     Position|Experience| Age|  Salary|          Company|Year Born|\n",
      "+---------------+-------------+----------+----+--------+-----------------+---------+\n",
      "|     Ivy Taylor|Data Engineer|       8.0|37.0| 75551.0|  Delta Analytics|   1986.0|\n",
      "|Charlie Johnson|Data Engineer|       4.0|59.0| 82748.0|        Beta Labs|   1964.0|\n",
      "|           null|Data Engineer|       4.0|64.0|117264.0|  Delta Solutions|   1959.0|\n",
      "|    Henry Davis|Data Engineer|       4.0|34.0|107322.0|   Beta Analytics|   1989.0|\n",
      "|   Alice Miller|Data Engineer|       4.0|35.0|100242.0|        Beta Labs|   1988.0|\n",
      "|   Henry Wilson|Data Engineer|       8.0|62.0| 72275.0|Beta Technologies|   1961.0|\n",
      "|     Jack Brown|Data Engineer|       5.0|44.0| 92677.0|             null|   1979.0|\n",
      "| David Williams|Data Engineer|       2.0|28.0| 93153.0| Meta Innovations|   1995.0|\n",
      "| Charlie Miller|Data Engineer|      10.0|28.0|101487.0|    Gamma Systems|   1995.0|\n",
      "|   Grace Wilson|Data Engineer|       1.0|null| 81649.0|       Delta Labs|     null|\n",
      "+---------------+-------------+----------+----+--------+-----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.filter((df_spark[\"Salary\"] >= 70000) & (df_spark[\"Position\"] == \"Data Engineer\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark GroupBy and Aggregate Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Apache Spark, the GroupBy and Aggregate functions are used for data aggregation and summarization. The `groupBy` operation is similar to its counterpart in pandas and is employed to group data based on one or more columns. Subsequently, aggregate functions, such as `sum`, `avg`, `max`, or custom aggregation expressions, are applied to the grouped data.\n",
    "\n",
    "Compared to pandas, Spark's GroupBy and Aggregate functions operate in a distributed manner, allowing them to handle large datasets that exceed the memory capacity of a single machine. While both pandas and Spark provide similar functionalities, Spark's distributed nature enables it to process vast amounts of data in parallel, making it advantageous for big data scenarios.\n",
    "\n",
    "In terms of speed, Spark's GroupBy and Aggregate operations may exhibit better performance on large-scale datasets compared to pandas, especially when leveraging the parallel processing capabilities of a Spark cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------+-----------+--------------+\n",
      "|            Position|max(Experience)|max(Age)|max(Salary)|max(Year Born)|\n",
      "+--------------------+---------------+--------+-----------+--------------+\n",
      "|                 CTO|           10.0|    65.0|   115678.0|        2004.0|\n",
      "|                  HR|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|                null|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|              Intern|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|           Developer|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|       Product Owner|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|Machine Learning ...|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|                 CFO|           10.0|    65.0|   117446.0|        2005.0|\n",
      "|                 CEO|           10.0|    64.0|   119662.0|        2005.0|\n",
      "|      Data Scientist|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|        Data Analyst|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|            Chairman|           10.0|    65.0|   114096.0|        2005.0|\n",
      "|        Board Member|           10.0|    65.0|   118234.0|        2005.0|\n",
      "|       AI Researcher|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|             Manager|           10.0|    65.0|   120000.0|        2005.0|\n",
      "|                 CMO|           10.0|    65.0|   119539.0|        2005.0|\n",
      "|                 COO|           10.0|    65.0|   119323.0|        2005.0|\n",
      "|       Data Engineer|           10.0|    65.0|   120000.0|        2005.0|\n",
      "+--------------------+---------------+--------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy('Position').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            Position| count|\n",
      "+--------------------+------+\n",
      "|                 CTO|    55|\n",
      "|                  HR|450842|\n",
      "|                null|500000|\n",
      "|              Intern|450314|\n",
      "|           Developer|448851|\n",
      "|       Product Owner|448808|\n",
      "|Machine Learning ...|449738|\n",
      "|                 CFO|    79|\n",
      "|                 CEO|    69|\n",
      "|      Data Scientist|450302|\n",
      "|        Data Analyst|450126|\n",
      "|            Chairman|    66|\n",
      "|        Board Member|    60|\n",
      "|       AI Researcher|450487|\n",
      "|             Manager|449975|\n",
      "|                 CMO|    67|\n",
      "|                 COO|    73|\n",
      "|       Data Engineer|450088|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy('Position').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|     sum(Salary)|\n",
      "+----------------+\n",
      "|2.87912402065E11|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregation\n",
    "df_spark.agg({'Salary':'Sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            Position|      avg(Salary)|\n",
      "+--------------------+-----------------+\n",
      "|                 CTO|57389.41176470588|\n",
      "|                  HR|64049.72387482003|\n",
      "|                null|63990.30724020897|\n",
      "|              Intern|63989.16718638214|\n",
      "|           Developer|64008.08671762606|\n",
      "|       Product Owner|63985.54207518261|\n",
      "|Machine Learning ...| 63862.1746125443|\n",
      "|                 CFO|65832.30985915494|\n",
      "|                 CEO|     64872.796875|\n",
      "|      Data Scientist|63996.87451278357|\n",
      "|        Data Analyst|63954.98347060536|\n",
      "|            Chairman|68150.79032258065|\n",
      "|        Board Member|57970.64705882353|\n",
      "|       AI Researcher|64024.12765505994|\n",
      "|             Manager| 63933.3196142544|\n",
      "|                 CMO|61796.13114754098|\n",
      "|                 COO|66257.74242424243|\n",
      "|       Data Engineer|63990.78019210973|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.groupBy('Position').agg({'Salary':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Imputer Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Apache Spark, the `Imputer` function is used for handling missing values in a DataFrame. It allows you to impute (fill in) missing values in specified columns by replacing them with a chosen strategy, such as mean, median, or a constant value. The `Imputer` function is particularly useful when dealing with datasets containing incomplete or null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(inputCols = ['Experience', 'Age', 'Salary'],outputCols=[\"{}_impute\".format(c) for c in ['Experience', 'Age', 'Salary']]).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+----+--------+------------------+---------+-----------------+-----------------+-------------+\n",
      "|     Full Name|            Position|Experience| Age|  Salary|           Company|Year Born|Experience_impute|       Age_impute|Salary_impute|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+-----------------+-----------------+-------------+\n",
      "|  Ivy Williams|       Product Owner|       8.0|30.0|117550.0|   Gamma Solutions|   1993.0|              8.0|             30.0|     117550.0|\n",
      "|  Bob Williams|        Data Analyst|       8.0|58.0| 26085.0|              null|   1965.0|              8.0|             58.0|      26085.0|\n",
      "|          null|Machine Learning ...|       2.0|51.0| 22728.0|     Alpha Systems|   1972.0|              2.0|             51.0|      22728.0|\n",
      "| Charlie Brown|        Data Analyst|       2.0|39.0| 38455.0|    Meta Analytics|   1984.0|              2.0|             39.0|      38455.0|\n",
      "|Frank Williams|       Product Owner|       4.0|57.0| 65109.0|        Gamma Labs|   1966.0|              4.0|             57.0|      65109.0|\n",
      "|Henry Williams|                null|       2.0|26.0| 81062.0| Meta Technologies|   1997.0|              2.0|             26.0|      81062.0|\n",
      "|          null|              Intern|      null|58.0| 53429.0|  Beta Innovations|   1965.0|5.001912222222222|             58.0|      53429.0|\n",
      "|          null|             Manager|       7.0|20.0| 37876.0|Delta Technologies|   2003.0|              7.0|             20.0|      37876.0|\n",
      "| Jack Williams|Machine Learning ...|       4.0|36.0| 10997.0|    Meta Analytics|   1987.0|              4.0|             36.0|      10997.0|\n",
      "|          null|                null|       3.0|null| 53073.0| Delta Innovations|     null|              3.0|41.49889266666667|      53073.0|\n",
      "+--------------+--------------------+----------+----+--------+------------------+---------+-----------------+-----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_spark).transform(df_spark).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
